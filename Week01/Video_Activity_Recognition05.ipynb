{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "VIDEO ACTIVITY RECOGNITION\n",
        "Real-World Problem:\n",
        "A security system wants to detect running vs walking from videos.\n",
        "Your Objective: Understand how video data is stored for ML.\n",
        "Tasks\n",
        "1. Simulate a 10-second video (30 FPS → 300 frames)\n",
        "2. Store as a tensor\n",
        "3. Add batch size\n",
        "Hint Code\n",
        "video = np.random.rand(1, 300, 224, 224, 3)\n",
        "print(video.shape)\n",
        "What You Learn\n",
        "•\tTime dimension\n",
        "•\tVideo tensors\n",
        "•\t3D CNN inputs\n"
      ],
      "metadata": {
        "id": "Z-oV4ALa6ZOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "yzAG3tsE6M-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Video Parameters"
      ],
      "metadata": {
        "id": "nNpZ_IdY61np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Video properties\n",
        "fps = 30              # Frames per second\n",
        "seconds = 10          # Video length\n",
        "frames = fps * seconds\n",
        "height = 224          # Frame height\n",
        "width = 224           # Frame width\n",
        "channels = 3          # RGB\n"
      ],
      "metadata": {
        "id": "FUCo1nPy60lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate Frames"
      ],
      "metadata": {
        "id": "dqSbFWCF6_JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames = np.random.rand(frames, height, width, channels)\n",
        "(300, 224, 224, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je7OTaZ568Z-",
        "outputId": "aea09e27-a415-49fa-be25-46f5c789c94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Batch Dimension"
      ],
      "metadata": {
        "id": "iDEvH4Sk7KqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_tensor = np.expand_dims(video_frames, axis=0)\n"
      ],
      "metadata": {
        "id": "wg0ETTdj7CKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print video tensers\n",
        "print(\"Video Tensor Shape:\", video_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ny8HBD7O-N",
        "outputId": "c6ac6fc3-3e6d-478f-aec3-3a81a5969586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Tensor Shape: (1, 300, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video Tensor Shape => (Batch size, Time(Frame), Frame Height, Frame Width, RGB Channels)"
      ],
      "metadata": {
        "id": "3WKO7kNZ7xM8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5L3W9KT7Tui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}